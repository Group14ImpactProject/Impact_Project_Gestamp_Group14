{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>IMPACT PROJECT - GESTAMP</center> \n## <center>Defect Detection using Machine Learning</center> \n### <center>Bayesian optimizer using Hyperopt</center>\n<center>Group 14</center>Â ","metadata":{}},{"cell_type":"markdown","source":"<img \n    src=\"https://www.gestamp.com/getattachment/c8d61c0f-e752-4156-8002-97e21ab43a3f/Imag2-2\" width=\"2400\" height=\"1000\" align=\"center\"/>","metadata":{}},{"cell_type":"markdown","source":"This notebook can be the 4 datasets","metadata":{}},{"cell_type":"markdown","source":"## <center>Table of Contents</center>\n1. [Split Dataset](#1)\n2. [Hyperparameters Tuning: Hyperopt](#2)\n3. [Model Training](#3)\n4. [Model Testing and Evaluating](#4)\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport sklearn\nfrom hyperopt import hp\nimport hyperopt","metadata":{"id":"PtVnTdyQB9H4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/binary-strat1-2/binary_strat2_le_ss.csv')\n","metadata":{"id":"EiEff4zXC9Ov","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='1'>**Split Dataset**</a>","metadata":{}},{"cell_type":"code","source":"X = data.drop('Defect', axis=1)\ny = data['Defect']","metadata":{"id":"6Mg1tMeUC-2q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.176, random_state=42, stratify=y_train)\n","metadata":{"id":"d6O3LduMDAG1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'>**Hyperparameters Tuning: Hyperopt**</a>","metadata":{}},{"cell_type":"code","source":"hyperparams = {\n  'gamma': hp.quniform('gamma', 1, 5, 1),\n  'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1),\n  'min_child_weight': hp.quniform('min_child_weight', 0, 10, 1),\n  'n_estimators': hp.quniform('n_estimators',1,100,1),\n  'max_depth': hp.quniform('max_depth',1,10,1),\n  'learning_rate': hp.uniform('learning_rate',0.01, 0.1)\n}","metadata":{"id":"FHHj5_LtRH4E","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(hyperparams):\n    hyperparams['max_depth'] = round(hyperparams['max_depth'])\n    hyperparams['n_estimators'] = round(hyperparams['n_estimators'])\n    return xgb.XGBClassifier(\n          **hyperparams,\n          objective='binary:logistic',\n          tree_method='hist',\n          enable_categorical=True,\n          eval_metric='auc',\n          # early_stopping_rounds=25,\n          n_jobs=-1,\n          seed=0,\n      )\n\n\ndef objective(hyperparams):\n    model = make_model(hyperparams)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n\n    y_hat = model.predict_proba(X_val)[:,1]\n    auc_val = sklearn.metrics.roc_auc_score(y_val,y_hat)\n\n    return {'loss': -auc_val, 'status': hyperopt.STATUS_OK }\n","metadata":{"id":"X0E8RJLY5r3Q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trials = hyperopt.Trials()\n\nbest_hyperparams = hyperopt.fmin(\n    fn=objective,\n    space=hyperparams,\n    algo=hyperopt.tpe.suggest,\n    max_evals=200,\n    trials=trials)","metadata":{"id":"N-7_GJeaiSMr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7deadabc-a359-4c1d-9f30-9fb6c1668ade","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_hyperparams","metadata":{"id":"-LHe0EK5DDJ6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'>**Model Training**</a>","metadata":{}},{"cell_type":"code","source":"model = make_model(best_hyperparams)\nmodel.fit(X_train, y_train, eval_set=[(X_val, y_val)])","metadata":{"id":"H9lFrlHUXuAt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb.plot_importance(model)","metadata":{"id":"Vhbe_PfkXxKT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the feature importances from the model\nimportance_dict = model.get_booster().get_score(importance_type='weight')\n\n# Creating a DataFrame from the importances\nimportance_df = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Importance'])\n\n# Sorting the DataFrame by importance (descending order)\nimportance_df = importance_df.sort_values('Importance', ascending=False)\n\n# Printing the table format\nprint(importance_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'>**Model Testing and Evaluation**</a>","metadata":{}},{"cell_type":"code","source":"y_pred_prob = model.predict_proba(X_test)[:, 1]\nauc = roc_auc_score(y_test, y_pred_prob)\nprint(\"AUC: {:.4f}\".format(auc))","metadata":{"id":"yvKVOxOTDSDR","trusted":true},"execution_count":null,"outputs":[]}]}